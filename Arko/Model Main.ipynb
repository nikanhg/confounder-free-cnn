{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "#not needed?\n",
    "import hydra\n",
    "from omegaconf import DictConfig\n",
    "#not needed?\n",
    "import sys\n",
    "#not needed?\n",
    "import yaml\n",
    "import torch\n",
    "import shutil\n",
    "#might not need this\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from operator import getitem\n",
    "from functools import reduce\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torch.utils.data.sampler import Sampler\n",
    "import torcheval.metrics as tm\n",
    "from hydra import initialize, compose\n",
    "import timm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " importing libraries and packages necessary for setting up a machine learning project using PyTorch, specifically for image processing tasks for OCT medical image analysis with a Convolutional Neural Network (CNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **os, sys:** These are standard Python modules used to interact with the operating system and the Python runtime environment. They are useful for handling file and directory paths, and system-specific functions, respectively.\n",
    "\n",
    "* **torch :** The main PyTorch library, that provides rich functionalities for tensor operations, automatic differentiation(techniques used for numerical computing for calculating the derivatives (or gradients)), and neural network layers.\n",
    "\n",
    "* **torch.nn:** This submodule of PyTorch contains modules and utilities specifically designed for building neural networks, such as different types of layers such as convolutional layers, activation functions.\n",
    "\n",
    "* **torchvision:** A companion package to PyTorch that provides tools and datasets for image processing, including pre-defined transforms, common datasets, and pre-trained models.\n",
    "\n",
    "* **torch.utils.data:** This includes utilities to load data, iterate through datasets, and make dataset management easier. 'DataLoader' is a critical class that provides an iterable over the given dataset, and 'Dataset' is a base class for making datasets.\n",
    "\n",
    "* **PIL (Python Imaging Library):** Used for opening, manipulating, and saving many different image file formats. This is essential in processing raw image files for model.\n",
    "\n",
    "* **shutil:** Provides a number of high-level operations on files and collections of files. In this project, it is used for copying files or entire folder contents.\n",
    "\n",
    "* **tqdm:** A library that provides a progress bar that can help visualize the progress of Python loops including during training loops or data loading.\n",
    "\n",
    "* **torch.utils.tensorboard:** Integrates PyTorch with TensorBoard, a visualization toolkit for machine learning experimentation. SummaryWriter allows logging of experiments, such as visualizing the model graph, parameters, and metrics during training.\n",
    "\n",
    "* **hydra, omegaconf:** These are configuration management tools. Hydra is used for elegantly configuring complex applications, and OmegaConf manages configurations as hierarchical structures, facilitating the handling of settings and parameters.\n",
    "\n",
    "* **timm:** Short for PyTorch Image Models, this library provides pre-trained models, model components, and utilities for image classification.\n",
    "\n",
    "* **torcheval.metrics (tm):** PyTorch library for evaluation metrics, helping in assessing the performance of model using various metrics like accuracy, precision, recall, etc.\n",
    "\n",
    "* **Sampler:** An abstract class in torch.utils.data that allows to specify the strategy to draw samples from the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input \n",
    "dir= \"C:/Users/baner/OneDrive/Desktop/New folder (2)/OCTDL\"\n",
    "dataset_folder = dir + \"/OCTDL images/\"\n",
    "#lables for each Input\n",
    "labels_path = dir + \"/OCTDL_labels.csv\"\n",
    "#Output\n",
    "output_folder = dir + \"/output\"\n",
    "#model save path\n",
    "save_path = dir + \"/run\"\n",
    "#Config file\n",
    "cg = dir + \"/configs/OCTDL.yaml\"\n",
    "config_path = dir + '/configs'\n",
    "\n",
    "regression_loss = ['mean_square_error', 'mean_absolute_error', 'smooth_L1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up paths and configuration details for deep learning model training for Optical Coherence Tomography (OCT) image analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed, deterministic=False):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = deterministic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function set_random_seed is designed to establish a consistent starting point for the random number generators used. Setting a random seed allows for reproducibility of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baner\\AppData\\Local\\Temp\\ipykernel_10888\\1333183673.py:6: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize(config_path=relative_cfg_path):\n"
     ]
    }
   ],
   "source": [
    "config_path =  dir + '/configs'\n",
    "config_name = \"OCTDL\"\n",
    "cwd = os.getcwd()\n",
    "# Convert the absolute config path to a relative path\n",
    "relative_cfg_path = os.path.relpath(config_path, cwd)\n",
    "with initialize(config_path=relative_cfg_path):\n",
    "    cfg = compose(config_name=config_name)\n",
    "\n",
    "if cfg.base.random_seed != -1:\n",
    "    seed = cfg.base.random_seed\n",
    "    set_random_seed(seed, cfg.base.cudnn_deterministic)\n",
    "log_path = os.path.join(cfg.base.save_path, 'log')\n",
    "logger = SummaryWriter(log_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is designed for robust configuration management and reproducibility, utilizing Hydra for dynamic configuration composition. The script sets up paths for configuration files and initializes Hydra with a relative path to the configuration directory. Upon successful initialization, it composes a configuration object named \"OCTDL\" based on YAML files located in the specified directory. The code ensures that if a specific random seed is provided in the configuration (not set to -1), it is applied using the set_random_seed function, which also configures PyTorch's CUDA backend to operate deterministically if specified. This ensures reproducible results, essential for experimental consistency and validation. Additionally, the script sets up a logging mechanism using TensorBoard's SummaryWriter, directing output to a designated log directory, facilitating detailed tracking and visualization of the training process. This structured approach not only enhances reproducibility but also simplifies managing diverse experimental setups and tuning parameters across different runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_out_features(num_classes, criterion):\n",
    "    out_features = num_classes\n",
    "    if criterion in regression_loss:\n",
    "        out_features = 1\n",
    "    return out_features\n",
    "\n",
    "def get_terminal_col():\n",
    "    try:\n",
    "        return os.get_terminal_size().columns\n",
    "    except OSError:\n",
    "        return 80\n",
    "\n",
    "def print_msg(msg, appendixs=[], warning=False):\n",
    "    color = '\\033[93m'\n",
    "    end = '\\033[0m'\n",
    "    print_fn = (lambda x: print(color + x + end)) if warning else print\n",
    "\n",
    "    max_len = len(max([msg, *appendixs], key=len))\n",
    "    max_len = min(max_len, get_terminal_col())\n",
    "    print_fn('=' * max_len)\n",
    "    print_fn(msg)\n",
    "    for appendix in appendixs:\n",
    "        print_fn(appendix)\n",
    "    print_fn('=' * max_len)\n",
    "\n",
    "def select_out_features(num_classes, criterion):\n",
    "    out_features = num_classes\n",
    "    if criterion in regression_loss:\n",
    "        out_features = 1\n",
    "    return out_features\n",
    "\n",
    "def build_model(cfg):\n",
    "    network = cfg.train.network\n",
    "    out_features = select_out_features(\n",
    "        cfg.data.num_classes,\n",
    "        cfg.train.criterion\n",
    "    )\n",
    "\n",
    "    if 'vit' in network or 'swin' in network:\n",
    "        model = timm.create_model(\n",
    "            network,\n",
    "            img_size=cfg.data.input_size,\n",
    "            in_chans=cfg.data.in_channels,\n",
    "            num_classes=out_features,\n",
    "            pretrained=cfg.train.pretrained,\n",
    "        )\n",
    "    else:\n",
    "        model = timm.create_model(\n",
    "            network,\n",
    "            in_chans=cfg.data.in_channels,\n",
    "            num_classes=out_features,\n",
    "            pretrained=cfg.train.pretrained,\n",
    "        )\n",
    "\n",
    "    return model\n",
    "\n",
    "def generate_model(cfg):\n",
    "    model = build_model(cfg)\n",
    "\n",
    "    if cfg.train.checkpoint:\n",
    "        weights = torch.load(cfg.train.checkpoint)\n",
    "        model.load_state_dict(weights, strict=True)\n",
    "        print_msg('Load weights form {}'.format(cfg.train.checkpoint))\n",
    "    model = model.to(cfg.base.device)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detailed explanation of each function, its parameters, and its role, particularly focusing on configuring, building, and initializing a machine learning model for image processing tasks:<br>\n",
    "\n",
    "**1. select_out_features(num_classes, criterion)**:<br>\n",
    "Purpose: Determines the number of output features for the model based on the training criterion. if classification then **num_classes** is number of output feature, and if regression, then 1.<br>\n",
    "\n",
    "Parameters: <br>\n",
    "* num_classes: The total number of classes in the classification task\n",
    "* criterion: The loss function or criterion being used for the model.\n",
    "\n",
    "Role: This function checks if the criterion is a regression. If it is, it sets the number of output features to 1. Otherwise, it is considered classification and sets the output features to the number of classes.<br>\n",
    "\n",
    "<br>**2. get_terminal_col()**:<br>\n",
    "Purpose: Retrieves the width of the terminal.<br>\n",
    "\n",
    "Role: The purpose of knowing the terminal width is to make sure that any output from your script looks neat and is formatted correctly to fit within the window without wrapping unexpectedly.<br>\n",
    "\n",
    "<br>**3. print_msg(msg, appendixs=[], warning=False)**:<br>\n",
    "Purpose: Prints a formatted message, with options to include additional lines (appendixes) and a warning mode that changes text color.<br>\n",
    "\n",
    "Parameters:<br>\n",
    "* msg: The main message to print.\n",
    "* appendixs: A list of additional strings to print after the main message.\n",
    "* warning: A boolean flag that, if True, prints the message in a warning-specific color (yellow).\n",
    "Role: This function is helpful for displaying important runtime information or errors clearly and attractively.<br>\n",
    "\n",
    "<br>**4. build_model(cfg)**:<br>\n",
    "Purpose: Builds a machine learning model using configurations specified in cfg.<br>\n",
    "\n",
    "Parameters:\n",
    "* cfg: configuration object that has all the details and configs of the model.\n",
    "\n",
    "Role: This function retrieves the model architecture from the configuration and determines the number of output features using the select_out_features function. It checks if the network is a vision transformer (like VGG16) and adjusts the model creation parameters accordingly using the timm library, which provides a collection of pre-trained and custom models. The function configures the model with the specified input size, number of channels, and pretrained weights(Determines whether to initialize the model with weights that have been previously trained) if available.<br>\n",
    "\n",
    "<br>timm.create(): also called **PyTorch Image Models**, used to instantiate a neural network model based on the specifications provided in the 'cfg' object. <br>\n",
    "* Selecting the Model Architecture \n",
    "* Number of Input Channels: Indicates the number of color channels in the input images. For instance, 3 for RGB images, 1 for grayscale.\n",
    "* Number of Classes\n",
    "* Pretrained Weights \n",
    "<br>timm provides access to a wide range of model architectures, including but not limited to traditional convolutional neural networks (CNNs) like ResNets, EfficientNets, and VGGs, as well as newer architectures such as Vision Transformers (ViT), MLP Mixers, and Swin Transformers. This variety allows to choose the model that best fits their specific needs or to experiment with different models for comparison purposes.<br>\n",
    "\n",
    "**5. generate_model(cfg)**\n",
    "<br>Purpose: Configures and initializes a model based on the provided configurations in **build_model(cfg)**, including loading pretrained weights if specified.<br>\n",
    "<br>Parameters:\n",
    "* cfg: A configuration object loaded possibly from a configuration that includes paths, model specifications, and other parameters.\n",
    "\n",
    "Role: This function first builds the model using **build_model(cfg)**. It then checks if there are any pretrained weights specified in the configuration and loads them. This is crucial for transfer learning scenarios where starting with a pretrained model can significantly improve performance. After loading the weights, it logs the action with a formatted message and moves the model to the specified computing device (like GPU). This function is key for setting up a model ready for training or evaluation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add info about vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_transform(input_size):\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((input_size, input_size)),\n",
    "        transforms.ToTensor()])\n",
    "\n",
    "\n",
    "def mean_and_std(train_dataset, batch_size, num_workers):\n",
    "    loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    num_samples = 0.\n",
    "    channel_mean = torch.Tensor([0., 0., 0.])\n",
    "    channel_std = torch.Tensor([0., 0., 0.])\n",
    "    for samples in tqdm(loader):\n",
    "        X, _ = samples\n",
    "        channel_mean += X.mean((2, 3)).sum(0)\n",
    "        num_samples += X.size(0)\n",
    "    channel_mean /= num_samples\n",
    "\n",
    "    for samples in tqdm(loader):\n",
    "        X, _ = samples\n",
    "        batch_samples = X.size(0)\n",
    "        X = X.permute(0, 2, 3, 1).reshape(-1, 3)\n",
    "        channel_std += ((X - channel_mean) ** 2).mean(0) * batch_samples\n",
    "    channel_std = torch.sqrt(channel_std / num_samples)\n",
    "\n",
    "    mean, std = channel_mean.tolist(), channel_std.tolist()\n",
    "    print('mean: {}'.format(mean))\n",
    "    print('std: {}'.format(std))\n",
    "    return mean, std\n",
    "\n",
    "def auto_statistics(data_path, input_size, batch_size, num_workers):\n",
    "    print('Calculating mean and std of training set for data normalization.')\n",
    "    transform = simple_transform(input_size)\n",
    "    train_path = os.path.join(data_path, 'train')\n",
    "    train_dataset = datasets.ImageFolder(train_path, transform=transform)\n",
    "\n",
    "    return mean_and_std(train_dataset, batch_size, num_workers)\n",
    "\n",
    "def random_apply(op, p):\n",
    "    return transforms.RandomApply([op], p=p)\n",
    "\n",
    "def data_transforms(cfg):\n",
    "    data_aug = cfg.data.data_augmentation\n",
    "    aug_args = cfg.data_augmentation_args\n",
    "\n",
    "    operations = {\n",
    "        'random_crop': random_apply(\n",
    "            transforms.RandomResizedCrop(\n",
    "                size=(cfg.data.input_size, cfg.data.input_size),\n",
    "                scale=aug_args.random_crop.scale,\n",
    "                ratio=aug_args.random_crop.ratio\n",
    "            ),\n",
    "            p=aug_args.random_crop.prob\n",
    "        ),\n",
    "        'horizontal_flip': transforms.RandomHorizontalFlip(\n",
    "            p=aug_args.horizontal_flip.prob\n",
    "        ),\n",
    "        'vertical_flip': transforms.RandomVerticalFlip(\n",
    "            p=aug_args.vertical_flip.prob\n",
    "        ),\n",
    "        'color_distortion': random_apply(\n",
    "            transforms.ColorJitter(\n",
    "                brightness=aug_args.color_distortion.brightness,\n",
    "                contrast=aug_args.color_distortion.contrast,\n",
    "                saturation=aug_args.color_distortion.saturation,\n",
    "                hue=aug_args.color_distortion.hue\n",
    "            ),\n",
    "            p=aug_args.color_distortion.prob\n",
    "        ),\n",
    "        'rotation': random_apply(\n",
    "            transforms.RandomRotation(\n",
    "                degrees=aug_args.rotation.degrees,\n",
    "                fill=aug_args.value_fill\n",
    "            ),\n",
    "            p=aug_args.rotation.prob\n",
    "        ),\n",
    "        'translation': random_apply(\n",
    "            transforms.RandomAffine(\n",
    "                degrees=0,\n",
    "                translate=aug_args.translation.range,\n",
    "                fill=aug_args.value_fill\n",
    "            ),\n",
    "            p=aug_args.translation.prob\n",
    "        ),\n",
    "        'grayscale': transforms.RandomGrayscale(\n",
    "            p=aug_args.grayscale.prob\n",
    "        ),\n",
    "        'gaussian_blur': random_apply(\n",
    "            transforms.GaussianBlur(\n",
    "                kernel_size=aug_args.gaussian_blur.kernel_size,\n",
    "                sigma=aug_args.gaussian_blur.sigma\n",
    "            ),\n",
    "            p=aug_args.gaussian_blur.prob\n",
    "        )\n",
    "    }\n",
    "\n",
    "    augmentations = []\n",
    "    for op in data_aug:\n",
    "        if op not in operations:\n",
    "            raise NotImplementedError('Not implemented data augmentation operations: {}'.format(op))\n",
    "        augmentations.append(operations[op])\n",
    "\n",
    "    normalization = [\n",
    "        transforms.Resize((cfg.data.input_size, cfg.data.input_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(cfg.data.mean, cfg.data.std)\n",
    "    ]\n",
    "\n",
    "    train_preprocess = transforms.Compose([\n",
    "        *augmentations,\n",
    "        *normalization\n",
    "    ])\n",
    "\n",
    "    test_preprocess = transforms.Compose(normalization)\n",
    "\n",
    "    return train_preprocess, test_preprocess\n",
    "\n",
    "\n",
    "def img_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')\n",
    "    \n",
    "class CustomizedImageFolder(datasets.ImageFolder):\n",
    "    def __init__(self, root, transform=None, target_transform=None, loader=img_loader):\n",
    "        super(CustomizedImageFolder, self).__init__(root, transform, target_transform, loader=loader)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.samples[index]\n",
    "        sample = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return sample, target\n",
    "    \n",
    "def generate_dataset_from_folder(data_path, train_transform, test_transform):\n",
    "    train_path = os.path.join(data_path, 'train')\n",
    "    test_path = os.path.join(data_path, 'test')\n",
    "    val_path = os.path.join(data_path, 'val')\n",
    "\n",
    "    train_dataset = CustomizedImageFolder(train_path, train_transform, loader=img_loader)\n",
    "    test_dataset = CustomizedImageFolder(test_path, test_transform, loader=img_loader)\n",
    "    val_dataset = CustomizedImageFolder(val_path, test_transform, loader=img_loader)\n",
    "\n",
    "    return train_dataset, test_dataset, val_dataset\n",
    "\n",
    "def print_dataset_info(datasets):\n",
    "    train_dataset, test_dataset, val_dataset = datasets\n",
    "    print('=========================')\n",
    "    print('Dataset Loaded.')\n",
    "    print('Categories:\\t{}'.format(len(train_dataset.classes)))\n",
    "    print('Training:\\t{}'.format(len(train_dataset)))\n",
    "    print('Validation:\\t{}'.format(len(val_dataset)))\n",
    "    print('Test:\\t\\t{}'.format(len(test_dataset)))\n",
    "    print('=========================')\n",
    "    \n",
    "def generate_dataset(cfg):\n",
    "    if cfg.data.mean == 'auto' or cfg.data.std == 'auto':\n",
    "        mean, std = auto_statistics(\n",
    "            cfg.base.data_path,\n",
    "            cfg.data.input_size,\n",
    "            cfg.train.batch_size,\n",
    "            cfg.train.num_workers\n",
    "        )\n",
    "        cfg.data.mean = mean\n",
    "        cfg.data.std = std\n",
    "\n",
    "    train_transform, test_transform = data_transforms(cfg)\n",
    "\n",
    "    data_splits = generate_dataset_from_folder(\n",
    "        cfg.base.data_path,\n",
    "        train_transform,\n",
    "        test_transform\n",
    "    )\n",
    "\n",
    "    print_dataset_info(data_splits)\n",
    "    return data_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Above code is tailored for image data preprocessing, transformation, and loading within a machine learning pipeline, particularly focusing on image classification tasks. Each function plays a specific role in handling and transforming the image data effectively. Here’s an explanation of the key functions and their roles:<br>\n",
    "\n",
    " **1. simple_transform(input_size):**<br>\n",
    " Purpose: Sets up a basic image transformation pipeline that resizes an image to a square of the specified size and converts it to a tensor.<br>\n",
    "\n",
    " Parameters:\n",
    " * input_size: The target size to which images will be resized.<br>\n",
    "\n",
    "**2. mean_and_std(train_dataset, batch_size, num_workers):**<br>\n",
    "Purpose: Computes the mean and standard deviation of all images in a dataset, which are critical for normalizing the dataset during training.<br>\n",
    "\n",
    "Parameters:\n",
    "* train_dataset: The dataset from which to compute the statistics.\n",
    "* batch_size: Number of images to process in one batch.\n",
    "* num_workers: Number of worker processes to use for loading the data.\n",
    "\n",
    "<br>Role: Calculates the mean and standard deviation of all images across each color channel in a given dataset. These statistics are important for normalizing the dataset during the preprocessing step of training a model. Understanding the average color intensity and variability in a dataset is crucial for effectively training neural networks. By normalizing images (i.e., subtracting the mean and dividing by the standard deviation), the model sees a more standardized and simplified version of the input during training.<br>\n",
    "\n",
    "**3. auto_statistics(data_path, input_size, batch_size, num_workers)**<br>\n",
    "Purpose: Automates the calculation of mean and standard deviation for a dataset stored at a specified path.<br>\n",
    "\n",
    "Parameters:\n",
    "* data_path: Path to the dataset.\n",
    "* input_size: Size to which images will be resized.\n",
    "* batch_size: Number of images in each batch for processing.\n",
    "* num_workers: Number of processes to use for data loading.\n",
    "\n",
    "<br>Role: Uses datasets.ImageFolder, a utility class from the torchvision.datasets module in PyTorch. It is specifically designed to simplify the process of loading image data from a directory structure where images are organized into folders, with each folder representing a class. This class is very useful for training image classification models, as it automatically handles the mapping of images to their corresponding labels based on the folder structure.<br>\n",
    "\n",
    "**4. data_transforms(cfg)**<br>\n",
    "Purpose: Creates complex data augmentation pipelines based on configurations provided in cfg.<br>\n",
    "Parameters:\n",
    "* cfg: Configuration object containing settings for data augmentation and other preprocessing details.\n",
    "\n",
    "<br>Role: Based on the configuration, this function constructs a series of transformations including flipping, color adjustments, contrast, brightness, etc, to augment the training data, helping improve the robustness of the model against overfitting and enhancing its ability to generalize.<br>\n",
    "\n",
    "**5. generate_dataset_from_folder(data_path, train_transform, test_transform)**<br>\n",
    "Purpose: Loads image data from specified directories and applies the appropriate transformations for training, testing, and validation datasets.<br>\n",
    "\n",
    "Parameters:\n",
    "* data_path: The base directory containing the dataset.\n",
    "* train_transform: Transformations to apply to the training data.\n",
    "* test_transform: Transformations to apply to the testing and validation data.\n",
    "\n",
    "<br>Role: Utilizes the CustomizedImageFolder to apply the specified transformations and organize the data into training, testing, and validation splits. The CustomizedImageFolder class in the provided code is a subclass of torchvision.datasets.ImageFolder. This customization extends the base functionality of ImageFolder to adapt or enhance how images are loaded and processed, which can be crucial for specific datasets or preprocessing requirements. auto_statistics() is used initially to determine the normalization parameters, which are then typically hardcoded or saved for use in the actual data transformations applied during model training, handled by CustomizedImageFolder.<br>\n",
    "\n",
    "**6. print_dataset_info(datasets)**<br>\n",
    "Purpose: Prints information about the loaded datasets to help verify their correctness and completeness.<br>\n",
    "\n",
    "Parameters:\n",
    "* datasets: A tuple containing the training, testing, and validation datasets.\n",
    "\n",
    "<br>Role: Displays the number of categories and the size of each dataset split, providing a quick summary that can help in understanding the dataset structure and ensuring that data loading is correct.<br>\n",
    "\n",
    "**7. generate_dataset(cfg)**<br>\n",
    "Purpose: Coordinates the overall process of dataset preparation mentioned in the above functions.<br>\n",
    "\n",
    "Parameters:\n",
    "* cfg: Configuration object with settings for data path, transformations, and other necessary parameters.\n",
    "\n",
    "<br>Role: Manages the flow of setting up datasets from initial statistics calculation to applying transformations and organizing data splits. This function ensures that the datasets are ready for use in training, testing, and validation phases of machine learning models.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_fn = {\n",
    "    'acc': tm.MulticlassAccuracy,\n",
    "    'f1': tm.MulticlassF1Score,\n",
    "    'auc': tm.MulticlassAUROC,\n",
    "    'precision': tm.MulticlassPrecision,\n",
    "    'recall': tm.MulticlassRecall\n",
    "}\n",
    "available_metrics = metrics_fn.keys()\n",
    "logits_required_metrics = ['auc']\n",
    "regression_based_metrics = ['mean_square_error', 'mean_absolute_error', 'smooth_L1']\n",
    "\n",
    "class Estimator():\n",
    "    def __init__(self, metrics, num_classes, criterion, average='macro', thresholds=None):\n",
    "        self.criterion = criterion\n",
    "        self.num_classes = num_classes\n",
    "        self.thresholds = [-0.5 + i for i in range(num_classes)] if not thresholds else thresholds\n",
    "\n",
    "        if criterion in regression_based_metrics and 'auc' in metrics:\n",
    "            metrics.remove('auc')\n",
    "            print_msg('AUC is not supported for regression based metrics {}.'.format(criterion), warning=True)\n",
    "\n",
    "        self.metrics = metrics\n",
    "        self.metrics_fn = {m: metrics_fn[m](num_classes=num_classes, average=average) for m in metrics}\n",
    "        self.conf_mat_fn = tm.MulticlassConfusionMatrix(num_classes=num_classes)\n",
    "\n",
    "    def update(self, predictions, targets):\n",
    "        targets = targets.data.cpu().long()\n",
    "        logits = predictions.data.cpu()\n",
    "        predictions = self.to_prediction(logits)\n",
    "\n",
    "        # update metrics\n",
    "        self.conf_mat_fn.update(predictions, targets)\n",
    "        for m in self.metrics_fn.keys():\n",
    "            if m in logits_required_metrics:\n",
    "                self.metrics_fn[m].update(logits, targets)\n",
    "            else:\n",
    "                self.metrics_fn[m].update(predictions, targets)\n",
    "\n",
    "    def get_scores(self, digits=-1):\n",
    "        scores = {m: self._compute(m, digits) for m in self.metrics}\n",
    "        return scores\n",
    "\n",
    "    def _compute(self, metric, digits=-1):\n",
    "        score = self.metrics_fn[metric].compute().item()\n",
    "        score = score if digits == -1 else round(score, digits)\n",
    "        return score\n",
    "    \n",
    "    def get_conf_mat(self):\n",
    "        return self.conf_mat_fn.compute().numpy().astype(int)\n",
    "\n",
    "    def reset(self):\n",
    "        for m in self.metrics_fn.keys():\n",
    "            self.metrics_fn[m].reset()\n",
    "        self.conf_mat_fn.reset()\n",
    "    \n",
    "    def to_prediction(self, predictions):\n",
    "        if self.criterion in regression_based_metrics:\n",
    "            predictions = torch.tensor([self.classify(p.item()) for p in predictions]).long()\n",
    "        else:\n",
    "            predictions = torch.argmax(predictions, dim=1).long()\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def classify(self, predict):\n",
    "        thresholds = self.thresholds\n",
    "        predict = max(predict, thresholds[0])\n",
    "        for i in reversed(range(len(thresholds))):\n",
    "            if predict >= thresholds[i]:\n",
    "                return i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Estimator class is a designed to manage and compute various metrics for evaluating machine learning models, particularly those used in classification tasks. This class is highly modular and adaptable to different types of machine learning problems, whether they involve simple classification, multiclass classification, or even regression with specific adjustments. Here’s a detailed breakdown of the class and its functionalities:<br>\n",
    "\n",
    "**Constructor: __init__(self, metrics, num_classes, criterion, average='macro', thresholds=None)**\n",
    "Purpose: Initializes the estimator with specific metrics, the number of classes, the type of criterion, and other optional settings.<br>\n",
    "Parameters:\n",
    "* metrics: A list of metric names that the estimator should compute, for our problem we are using AUC, F1, accuracy, precision and recall.\n",
    "* num_classes: The total number of classes in the classification problem.\n",
    "* criterion: The criterion used for training the model, for our problem we are using cross_entropy.\n",
    "* average: Specifies the method for averaging in case of multiclass or multicategory metrics.\n",
    "* thresholds: Custom thresholds for classifying numerical outputs into categories, particularly useful in regression or other continuous output models.<br>\n",
    "\n",
    "**1. update(self, predictions, targets)**\n",
    "Purpose: Updates the metric calculations based on the latest batch of predictions and actual targets.<br>\n",
    "\n",
    "Parameters:\n",
    "* predictions: These are typically the raw output from the model, which can be logits (pre-activation outputs) for a classification task.\n",
    "* targets: These are the ground truth labels against which the model’s outputs are compared.\n",
    "\n",
    "<br>Role: The method begins by ensuring that both predictions and targets are moved to the CPU and converted to the appropriate tensor type (long integers) if necessary. This is done using targets.data.cpu().long().Then the raw predictions are processed into class labels using the to_prediction method. Finally updates the metrics used like AUC, confusion metric, acc, etc.<br>\n",
    "\n",
    "**2. get_scores(self, digits=-1)**\n",
    "Purpose: Retrieves the computed scores for all metrics after rounding them to the specified number of decimal places, then returns a dictionary of metric names and their corresponding scores.<br>\n",
    "\n",
    "**3. get_conf_mat(self)**\n",
    "Purpose: Computes and returns the current state of the confusion matrix.<br>\n",
    "\n",
    "**4. reset(self)**\n",
    "Purpose: Resets all metrics and the confusion matrix to start fresh, typically used between training epochs or different phases of model evaluation.<br>\n",
    "\n",
    "**5. to_prediction(self, predictions)**\n",
    "Purpose: Converts raw model outputs (logits or regression outputs) into discrete class predictions. For classification tasks, it simply takes the argmax of logits to determine the class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cross entropy, AUC, F1, ACCURACY, Precision and Recall. Argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating mean and std of training set for data normalization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:08<00:00,  2.24s/it]\n",
      "100%|██████████| 4/4 [00:08<00:00,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: [0.08801376819610596, 0.08801379799842834, 0.08801349997520447]\n",
      "std: [0.16029858589172363, 0.16029863059520721, 0.16029848158359528]\n",
      "=========================\n",
      "Dataset Loaded.\n",
      "Categories:\t3\n",
      "Training:\t241\n",
      "Validation:\t59\n",
      "Test:\t\t118\n",
      "=========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "model = generate_model(cfg)\n",
    "train_dataset, test_dataset, val_dataset = generate_dataset(cfg)\n",
    "estimator = Estimator(cfg.train.metrics, cfg.data.num_classes, cfg.train.criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configuration and Initialization:**\n",
    "* **Configuration Setup**: Using Hydra, a configuration management library, the system initializes settings from configuration files stored in a directory. This setup involves converting absolute paths to relative ones for robustness and setting the working environment based on the specified configuration (cfg). This step is crucial for maintaining consistency across different runtime environments and for flexibility in experimentation.\n",
    "* **Random Seed Setting**: The system sets a random seed to ensure reproducibility of results. This includes seeding the Python random module, NumPy's random number generator, and PyTorch's random functions, as well as configuring CUDA's deterministic mode if required.<br>\n",
    "\n",
    "**Model Preparation:**\n",
    "* **Model Generation:** Generate_model(cfg) constructs the neural network based on the specifications in cfg, which includes selecting the network architecture, loading any pretrained weights if specified, and ensuring the model is compatible with the designated computing device (e.g., GPU). This step is fundamental for leveraging transfer learning and custom architectures to address specific task needs.\n",
    "* **Data Management:**\n",
    "Dataset Handling: The generate_dataset(cfg) function orchestrates the loading and preprocessing of image data from specified directories. It handles:\n",
    "* Calculating dataset-specific statistics (mean and standard deviation) for normalization purposes, if not already specified.\n",
    "* Applying specified data transformations and augmentations to enhance model training and generalization capabilities. This includes resizing, cropping, flipping, and color adjustments.\n",
    "* Organizing data into training, validation, and testing datasets using a customized loader that might include specific preprocessing or formatting aligned with the model's input requirements.<br>\n",
    "\n",
    "**Performance Monitoring and Evaluation:**\n",
    "* **Estimator Setup:** An Estimator instance is initialized with configurations for performance metrics such as accuracy, F1-score, and others relevant to classification tasks. This tool is designed to continuously evaluate the model’s performance during training, providing insights into how well the model is learning and predicting across various classes.\n",
    "* **Metrics Management:** The Estimator is capable of handling both traditional classification metrics and specific adjustments for tasks that might output or interpret results in a regression-like manner (using thresholds to classify outputs). It ensures that all evaluations are appropriately updated and reported, aiding in model tuning and decision-making.<br>\n",
    "\n",
    "**Training Loop Execution:**\n",
    "* **Training Execution:** Using the prepared model and datasets, the training process would be executed, likely involving multiple epochs of passing the training data through the model, calculating loss, and updating model weights.\n",
    "\n",
    "* **Validation and Adjustment:** Post each training epoch, the model would be evaluated against the validation set to monitor performance improvements and make adjustments (like learning rate changes or early stopping) based on predefined criteria or performance metrics.\n",
    "* **Testing and Final Evaluation:** Once training is deemed complete, the model would be tested against the unseen test dataset to gauge its generalization capabilities and final performance metrics would be calculated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarmupLRScheduler():\n",
    "    def __init__(self, optimizer, warmup_epochs, initial_lr):\n",
    "        self.epoch = 0\n",
    "        self.optimizer = optimizer\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.initial_lr = initial_lr\n",
    "\n",
    "    def step(self):\n",
    "        if self.epoch <= self.warmup_epochs:\n",
    "            self.epoch += 1\n",
    "            curr_lr = (self.epoch / self.warmup_epochs) * self.initial_lr\n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                param_group['lr'] = curr_lr\n",
    "\n",
    "    def is_finish(self):\n",
    "        return self.epoch >= self.warmup_epochs\n",
    "\n",
    "\n",
    "class ScheduledWeightedSampler(Sampler):\n",
    "    def __init__(self, dataset, decay_rate):\n",
    "        self.dataset = dataset\n",
    "        self.decay_rate = decay_rate\n",
    "\n",
    "        self.num_samples = len(dataset)\n",
    "        self.targets = [sample[1] for sample in dataset.imgs]\n",
    "        self.class_weights = self.cal_class_weights()\n",
    "\n",
    "        self.epoch = 0\n",
    "        self.w0 = torch.as_tensor(self.class_weights, dtype=torch.double)\n",
    "        self.wf = torch.as_tensor([1] * len(self.dataset.classes), dtype=torch.double)\n",
    "        self.sample_weight = torch.zeros(self.num_samples, dtype=torch.double)\n",
    "        for i, _class in enumerate(self.targets):\n",
    "            self.sample_weight[i] = self.w0[_class]\n",
    "\n",
    "    def step(self):\n",
    "        if self.decay_rate < 1:\n",
    "            self.epoch += 1\n",
    "            factor = self.decay_rate**(self.epoch - 1)\n",
    "            self.weights = factor * self.w0 + (1 - factor) * self.wf\n",
    "            for i, _class in enumerate(self.targets):\n",
    "                self.sample_weight[i] = self.weights[_class]\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(torch.multinomial(self.sample_weight, self.num_samples, replacement=True).tolist())\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def cal_class_weights(self):\n",
    "        num_classes = len(self.dataset.classes)\n",
    "        classes_idx = list(range(num_classes))\n",
    "        class_count = [self.targets.count(i) for i in classes_idx]\n",
    "        weights = [self.num_samples / class_count[i] for i in classes_idx]\n",
    "        min_weight = min(weights)\n",
    "        class_weights = [weights[i] / min_weight for i in classes_idx]\n",
    "        return class_weights\n",
    "\n",
    "\n",
    "class LossWeightsScheduler():\n",
    "    def __init__(self, dataset, decay_rate):\n",
    "        self.dataset = dataset\n",
    "        self.decay_rate = decay_rate\n",
    "\n",
    "\n",
    "        self.num_samples = len(dataset)\n",
    "        self.targets = [sample[1] for sample in dataset.imgs]\n",
    "        self.class_weights = self.cal_class_weights()\n",
    "\n",
    "        self.epoch = 0\n",
    "        self.w0 = torch.as_tensor(self.class_weights, dtype=torch.float32)\n",
    "        self.wf = torch.as_tensor([1] * len(self.dataset.classes), dtype=torch.float32)\n",
    "\n",
    "    def step(self):\n",
    "        weights = self.w0\n",
    "        if self.decay_rate < 1:\n",
    "            self.epoch += 1\n",
    "            factor = self.decay_rate**(self.epoch - 1)\n",
    "            weights = factor * self.w0 + (1 - factor) * self.wf\n",
    "        return weights\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def cal_class_weights(self):\n",
    "        num_classes = len(self.dataset.classes)\n",
    "        classes_idx = list(range(num_classes))\n",
    "        class_count = [self.targets.count(i) for i in classes_idx]\n",
    "        weights = [self.num_samples / class_count[i] for i in classes_idx]\n",
    "        min_weight = min(weights)\n",
    "        class_weights = [weights[i] / min_weight for i in classes_idx]\n",
    "        return class_weights\n",
    "\n",
    "\n",
    "class ClippedCosineAnnealingLR():\n",
    "    def __init__(self, optimizer, T_max, min_lr):\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_max)\n",
    "        self.min_lr = min_lr\n",
    "        self.finish = False\n",
    "\n",
    "    def step(self):\n",
    "        if not self.finish:\n",
    "            self.scheduler.step()\n",
    "            curr_lr = self.optimizer.param_groups[0]['lr']\n",
    "            if curr_lr < self.min_lr:\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr'] = self.min_lr\n",
    "                self.finish = True\n",
    "\n",
    "    def is_finish(self):\n",
    "        return self.finish\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "above functions Particularly focusing on learning rates, sampling strategies, and loss weights. Let’s break down each class and function to understand their purpose, role, and parameters:\n",
    "\n",
    "### Learning Rate Scheduler:<br>\n",
    "\n",
    "In machine learning, particularly in training deep neural networks, a learning rate scheduler adjusts the learning rate during training according to a pre-defined strategy. It systematically modifies the learning rate based on certain criteria, which could include the number of epochs completed, the rate of error reduction, or performance metrics on a validation set.\n",
    "\n",
    "### Warmup in Learning Rate Scheduling<br>\n",
    "A warmup scheduler is a type of learning rate scheduler that initially starts with a smaller learning rate and gradually increases it to a pre-defined target rate over a certain number of epochs or steps.\n",
    "\n",
    "**1. WarmupLRScheduler:**<br>\n",
    "Purpose: Gradually increases the learning rate from zero to the initial specified learning rate over a given number of epochs. This approach helps stabilize the model's training early on, preventing large gradient updates that could destabilize the optimizer.\n",
    "\n",
    "Parameters:\n",
    "\n",
    "* optimizer: The optimizer associated with the model, whose learning rate will be adjusted.\n",
    "* warmup_epochs: The number of epochs over which the learning rate will increase.\n",
    "* initial_lr: The target learning rate after the warmup period.\n",
    "\n",
    "Role:\n",
    "* On each step(), the learning rate for each parameter group in the optimizer is adjusted based on the current epoch, increasing until it reaches the initial learning rate after the specified number of warmup epochs.\n",
    "\n",
    "* is_finish(): Checks if the warmup period is complete.\n",
    "\n",
    "**2. ScheduledWeightedSampler:**<br>\n",
    "Purpose: To adjust the sampling of training data according to class weights that change over time, ensuring that classes are sampled in a balanced manner as training progresses. This helps in dealing with imbalanced datasets.\n",
    "\n",
    "Parameters:\n",
    "* dataset: The dataset from which samples are drawn.\n",
    "* decay_rate: A rate at which the influence of initial class weights decreases over time.\n",
    "\n",
    "Role:\n",
    "* Initialization:It starts by calculating initial weights for each class based on their frequency in the dataset. Classes that appear less frequently get higher weights, making it more likely for samples from these classes to be chosen during training. This helps to compensate for their lower natural frequency.It stores these weights and prepares to adjust them over time.\n",
    "* Weight Adjustment Over Time:The sampler uses a decay_rate to decrease the influence of these initial weights gradually. The idea is to start the training focusing heavily on the imbalanced nature by sampling rarer classes more frequently. As training progresses, the weights slowly shift towards uniform weights, where every class has the same chance of being sampled. This transition is controlled by the decay_rate—a value between 0 and 1 that dictates how fast the weights shift towards being equal.\n",
    "* Each epoch, it recalculates the weights for each class by mixing the initial calculated weights with uniform weights based on how many epochs have passed.\n",
    "* For each batch of training data, the sampler uses these adjusted weights to randomly select which samples to include. This random selection is weighted, meaning samples from classes with higher weights are more likely to be chosen.\n",
    "\n",
    "**3. LossWeightsScheduler:**<br>\n",
    "Purpose: Similar to ScheduledWeightedSampler, but instead of adjusting sample weights, it adjusts the weights for the loss function to focus on certain classes more than others across training epochs. Rare classes are assigned higher weights, and frequent classes are given lower weights. \n",
    "\n",
    "Parameters:\n",
    "* dataset: The dataset being used, including class information.\n",
    "* decay_rate: The rate at which initial class weights decay to uniform.\n",
    "\n",
    "Role:\n",
    "step() adjusts the loss weights for each epoch, whi\n",
    "ch can then be used in a weighted loss function to help the model focus on underrepresented classes.\n",
    "\n",
    "**4. ClippedCosineAnnealingLR:**<br>\n",
    "Purpose: The ClippedCosineAnnealingLR class provides a strategy to manage the learning rate during the training of a machine learning model, specifically adapting the learning rate according to a cosine annealing schedule but ensuring it doesn’t fall below a certain minimum threshold.\n",
    "\n",
    "Parameters:\n",
    "* optimizer: The optimizer being used.\n",
    "* T_max: The maximum number of iterations/epochs before the learning rate resets.\n",
    "* min_lr: The minimum learning rate to which the learning rate can decay.\n",
    "Role:\n",
    "On each step(), the learning rate is adjusted using the internal scheduler. If it falls below min_lr, it is clipped to min_lr. This prevents the learning rate from becoming too low, which could stall the training process.<br>\n",
    "A learning rate that's too high can cause the model to converge too rapidly to suboptimal solutions, while a rate that’s too low might result in slow convergence or getting stuck in local minima. The ClippedCosineAnnealingLR class is designed to dynamically adjust the learning rate in a cyclical manner while preventing it from dropping too low, which helps maintain a balance between exploration of the solution space (avoiding local minima) and exploitation (fine-tuning to the best solution).<br>\n",
    "\n",
    "**Cosine Annealing:**<br>\n",
    "Cosine annealing modifies the learning rate following a cosine curve over a predefined number of epochs or cycles. This curve starts at a higher learning rate and decreases to a lower rate towards the end of a cycle, then resets to the higher rate at the start of a new cycle.<br>\n",
    "\n",
    "**Clipping the Learning Rate:**<br>\n",
    "The 'clipping' feature of this scheduler ensures that the learning rate never falls below a specified minimum threshold (min_lr). Even as the cosine annealing formula decreases the learning rate, this class checks if the rate has dropped below the minimum and, if so, sets it back to this minimum value.This is crucial because a very low learning rate can effectively freeze the model’s training, preventing significant updates to the weights and thus halting improvement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine annealing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_optimizer(cfg, model):\n",
    "    optimizer_strategy = cfg.solver.optimizer\n",
    "    learning_rate = cfg.solver.learning_rate\n",
    "    weight_decay = cfg.solver.weight_decay\n",
    "    momentum = cfg.solver.momentum\n",
    "    nesterov = cfg.solver.nesterov\n",
    "    adamw_betas = cfg.solver.adamw_betas\n",
    "\n",
    "    if optimizer_strategy == 'SGD':\n",
    "        optimizer = torch.optim.SGD(\n",
    "            model.parameters(),\n",
    "            lr=learning_rate,\n",
    "            momentum=momentum,\n",
    "            nesterov=nesterov,\n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "    elif optimizer_strategy == 'ADAM':\n",
    "        optimizer = torch.optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=learning_rate,\n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "    elif optimizer_strategy == 'ADAMW':\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=learning_rate,\n",
    "            betas=adamw_betas,\n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError('Not implemented optimizer.')\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "def initialize_sampler(cfg, train_dataset, val_dataset):\n",
    "    sampling_strategy = cfg.data.sampling_strategy\n",
    "    val_sampler = None\n",
    "    if sampling_strategy == 'class_balanced':\n",
    "        train_sampler = ScheduledWeightedSampler(train_dataset, 1)\n",
    "    elif sampling_strategy == 'progressively_balanced':\n",
    "        train_sampler = ScheduledWeightedSampler(train_dataset, cfg.data.sampling_weights_decay_rate)\n",
    "    elif sampling_strategy == 'instance_balanced':\n",
    "        train_sampler = None\n",
    "    else:\n",
    "        raise NotImplementedError('Not implemented resampling strategy.')\n",
    "\n",
    "    return train_sampler, val_sampler\n",
    "\n",
    "def initialize_lr_scheduler(cfg, optimizer):\n",
    "    warmup_epochs = cfg.train.warmup_epochs\n",
    "    learning_rate = cfg.solver.learning_rate\n",
    "    scheduler_strategy = cfg.solver.lr_scheduler\n",
    "\n",
    "    if not scheduler_strategy:\n",
    "        lr_scheduler = None\n",
    "    else:\n",
    "        scheduler_args = cfg.scheduler_args[scheduler_strategy]\n",
    "        if scheduler_strategy == 'cosine':\n",
    "            lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, **scheduler_args)\n",
    "        elif scheduler_strategy == 'multiple_steps':\n",
    "            lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, **scheduler_args)\n",
    "        elif scheduler_strategy == 'reduce_on_plateau':\n",
    "            lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, **scheduler_args)\n",
    "        elif scheduler_strategy == 'exponential':\n",
    "            lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, **scheduler_args)\n",
    "        elif scheduler_strategy == 'clipped_cosine':\n",
    "            lr_scheduler = ClippedCosineAnnealingLR(optimizer, **scheduler_args)\n",
    "        else:\n",
    "            raise NotImplementedError('Not implemented learning rate scheduler.')\n",
    "\n",
    "    if warmup_epochs > 0:\n",
    "        warmup_scheduler = WarmupLRScheduler(optimizer, warmup_epochs, learning_rate)\n",
    "    else:\n",
    "        warmup_scheduler = None\n",
    "\n",
    "    return lr_scheduler, warmup_scheduler\n",
    "\n",
    "class WarpedLoss():\n",
    "    def __init__(self, loss_function, criterion):\n",
    "        self.loss_function = loss_function\n",
    "        self.criterion = criterion\n",
    "\n",
    "        self.squeeze = True if self.criterion in regression_loss else False\n",
    "\n",
    "    def __call__(self, pred, target):\n",
    "        if self.squeeze:\n",
    "            pred = pred.squeeze()\n",
    "\n",
    "        return self.loss_function(pred, target)\n",
    "def initialize_loss(cfg, train_dataset):\n",
    "\n",
    "    criterion = cfg.train.criterion\n",
    "    criterion_args = cfg.criterion_args[criterion]\n",
    "\n",
    "    weight = None\n",
    "    loss_weight_scheduler = None\n",
    "    loss_weight = cfg.train.loss_weight\n",
    "    if criterion == 'cross_entropy':\n",
    "        if loss_weight == 'balance':\n",
    "            loss_weight_scheduler = LossWeightsScheduler(train_dataset, 1)\n",
    "        elif loss_weight == 'dynamic':\n",
    "            loss_weight_scheduler = LossWeightsScheduler(train_dataset, cfg.train.loss_weight_decay_rate)\n",
    "        elif isinstance(loss_weight, list):\n",
    "            assert len(loss_weight) == len(train_dataset.classes)\n",
    "            weight = torch.as_tensor(loss_weight, dtype=torch.float32, device=cfg.base.device)\n",
    "        loss = nn.CrossEntropyLoss(weight=weight, **criterion_args)\n",
    "    elif criterion == 'mean_square_error':\n",
    "        loss = nn.MSELoss(**criterion_args)\n",
    "    elif criterion == 'mean_absolute_error':\n",
    "        loss = nn.L1Loss(**criterion_args)\n",
    "    elif criterion == 'smooth_L1':\n",
    "        loss = nn.SmoothL1Loss(**criterion_args)\n",
    "    elif criterion == 'kappa_loss':\n",
    "        loss = KappaLoss(**criterion_args)\n",
    "    elif criterion == 'focal_loss':\n",
    "        loss = FocalLoss(**criterion_args)\n",
    "    else:\n",
    "        raise NotImplementedError('Not implemented loss function.')\n",
    "\n",
    "    loss_function = WarpedLoss(loss, criterion)\n",
    "    return loss_function, loss_weight_scheduler\n",
    "\n",
    "def initialize_dataloader(cfg, train_dataset, val_dataset, train_sampler, val_sampler):\n",
    "    batch_size = cfg.train.batch_size\n",
    "    num_workers = cfg.train.num_workers\n",
    "    pin_memory = cfg.train.pin_memory\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=(train_sampler is None),\n",
    "        sampler=train_sampler,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "        pin_memory=pin_memory\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=(val_sampler is None),\n",
    "        sampler=val_sampler,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=False,\n",
    "        pin_memory=pin_memory\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def save_weights(model, save_path):\n",
    "    if isinstance(model, nn.DataParallel) or isinstance(model, nn.parallel.DistributedDataParallel):\n",
    "        state_dict = model.module.state_dict()\n",
    "    else:\n",
    "        state_dict = model.state_dict()\n",
    "    torch.save(state_dict, save_path)\n",
    "\n",
    "def inverse_normalize(tensor, mean, std):\n",
    "    for t, m, s in zip(tensor, mean, std):\n",
    "        t.mul_(s).add_(m)\n",
    "    return tensor\n",
    "\n",
    "def select_target_type(y, criterion):\n",
    "    if criterion in ['cross_entropy', 'kappa_loss']:\n",
    "        y = y.long()\n",
    "    elif criterion in ['mean_square_error', 'mean_absolute_error', 'smooth_L1']:\n",
    "        y = y.float()\n",
    "    elif criterion in ['focal_loss']:\n",
    "        y = y.to(dtype=torch.int64)\n",
    "    else:\n",
    "        raise NotImplementedError('Not implemented criterion.')\n",
    "    return y\n",
    "\n",
    "def train(cfg, model, train_dataset, val_dataset, estimator, logger=None):\n",
    "\n",
    "    device = cfg.base.device\n",
    "    optimizer = initialize_optimizer(cfg, model)\n",
    "    train_sampler, val_sampler = initialize_sampler(cfg, train_dataset, val_dataset)\n",
    "    lr_scheduler, warmup_scheduler = initialize_lr_scheduler(cfg, optimizer)\n",
    "    loss_function, loss_weight_scheduler = initialize_loss(cfg, train_dataset)\n",
    "    train_loader, val_loader = initialize_dataloader(cfg, train_dataset, val_dataset, train_sampler, val_sampler)\n",
    "\n",
    "    # start training\n",
    "    model.train()\n",
    "    avg_loss = 0\n",
    "    max_indicator = 0\n",
    "    for epoch in range(1, cfg.train.epochs + 1):\n",
    "        # resampling weight update\n",
    "        if train_sampler:\n",
    "            train_sampler.step()\n",
    "\n",
    "        # update loss weights\n",
    "        if loss_weight_scheduler:\n",
    "            weight = loss_weight_scheduler.step()\n",
    "            loss_function.weight = weight.to(device)\n",
    "\n",
    "        # warmup scheduler update\n",
    "        if warmup_scheduler and not warmup_scheduler.is_finish():\n",
    "            warmup_scheduler.step()\n",
    "\n",
    "        epoch_loss = 0\n",
    "        estimator.reset()\n",
    "        progress = tqdm(enumerate(train_loader), total=len(train_loader)) if cfg.base.progress else enumerate(train_loader)\n",
    "        for step, train_data in progress:\n",
    "            X, y = train_data\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y = select_target_type(y, cfg.train.criterion)\n",
    "\n",
    "            # forward\n",
    "            y_pred = model(X)\n",
    "            loss = loss_function(y_pred, y)\n",
    "\n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # metrics\n",
    "            epoch_loss += loss.item()\n",
    "            avg_loss = epoch_loss / (step + 1)\n",
    "\n",
    "            estimator.update(y_pred, y)\n",
    "            message = 'epoch: [{} / {}], loss: {:.6f}'.format(epoch, cfg.train.epochs, avg_loss)\n",
    "            if cfg.base.progress:\n",
    "                progress.set_description(message)\n",
    "\n",
    "        if not cfg.base.progress:\n",
    "            print(message)\n",
    "\n",
    "        train_scores = estimator.get_scores(4)\n",
    "        scores_txt = ', '.join(['{}: {}'.format(metric, score) for metric, score in train_scores.items()])\n",
    "        print('Training metrics:', scores_txt)\n",
    "\n",
    "        curr_lr = optimizer.param_groups[0]['lr']\n",
    "        if logger:\n",
    "            for metric, score in train_scores.items():\n",
    "                logger.add_scalar('training {}'.format(metric), score, epoch)\n",
    "            logger.add_scalar('training loss', avg_loss, epoch)\n",
    "            logger.add_scalar('learning rate', curr_lr, epoch)\n",
    "\n",
    "        if cfg.train.sample_view:\n",
    "            samples = torchvision.utils.make_grid(X)\n",
    "            samples = inverse_normalize(samples, cfg.data.mean, cfg.data.std)\n",
    "            logger.add_image('input samples', samples, epoch, dataformats='CHW')\n",
    "\n",
    "        # validation performance\n",
    "        if epoch % cfg.train.eval_interval == 0:\n",
    "            eval(cfg, model, val_loader, cfg.train.criterion, estimator, device)\n",
    "            val_scores = estimator.get_scores(6)\n",
    "            scores_txt = ['{}: {}'.format(metric, score) for metric, score in val_scores.items()]\n",
    "            print_msg('Validation metrics:', scores_txt)\n",
    "            if logger:\n",
    "                for metric, score in val_scores.items():\n",
    "                    logger.add_scalar('validation {}'.format(metric), score, epoch)\n",
    "\n",
    "            # save model\n",
    "            indicator = val_scores[cfg.train.indicator]\n",
    "            if indicator > max_indicator:\n",
    "                save_weights(model, os.path.join(cfg.base.save_path, 'best_validation_weights.pt'))\n",
    "                max_indicator = indicator\n",
    "                print_msg('Best {} in validation set. Model save at {}'.format(cfg.train.indicator, cfg.base.save_path))\n",
    "\n",
    "        if epoch % cfg.train.save_interval == 0:\n",
    "            save_weights(model, os.path.join(cfg.base.save_path, 'epoch_{}.pt'.format(epoch)))\n",
    "\n",
    "        # update learning rate\n",
    "        if lr_scheduler and (not warmup_scheduler or warmup_scheduler.is_finish()):\n",
    "            if cfg.solver.lr_scheduler == 'reduce_on_plateau':\n",
    "                lr_scheduler.step(avg_loss)\n",
    "            else:\n",
    "                lr_scheduler.step()\n",
    "\n",
    "    # save final model\n",
    "    save_weights(model, os.path.join(cfg.base.save_path, 'final_weights.pt'))\n",
    "\n",
    "    if logger:\n",
    "        logger.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These components work together to provide a comprehensive, configurable, and adaptable framework for training a CNN on OCT images, with considerations for imbalanced data, dynamic learning rate adjustments, and robust loss management to ensure optimal training performance.\n",
    "\n",
    "**1. initialize_optimizer:**<br>\n",
    "Purpose: Configures and initializes the optimizer used for training the model.<br>\n",
    "Parameters:\n",
    "* cfg: Configuration object containing optimizer settings.\n",
    "* model: The neural network model for which the optimizer is being set.\n",
    "\n",
    "Role: This function selects the optimizer based on configuration settings (cfg). Depending on the choice, it initializes ADAM with specific parameters like learning rate, weight decay, etc.\n",
    "\n",
    "**2. initialize_sampler:**<br>\n",
    "Purpose: Sets up sampling strategies for the training dataset.<br>\n",
    "Parameters:\n",
    "* cfg: Configuration containing sampling strategy information.\n",
    "* train_dataset: The dataset used for training.\n",
    "* val_dataset: The dataset used for validation (though not directly used here).\n",
    "Role: Depending on the configuration, this function can initialize different types of samplers, such as ScheduledWeightedSampler(), to handle class imbalance by adjusting sample weights across training epochs.\n",
    "\n",
    "**3. initialize_lr_scheduler:**<br>\n",
    "Purpose: Configures and creates a learning rate scheduler.<br>\n",
    "Parameters:\n",
    "* cfg: Configuration containing scheduler type and parameters.\n",
    "* optimizer: The optimizer to which the scheduler will be applied.\n",
    "Role: This function supports multiple types of learning rate schedulers, allowing dynamic adjustment of learning rates based on training progress. It can also integrate a warmup period through WarmupLRScheduler() to gradually ramp up the learning rate.\n",
    "\n",
    "**4. WarpedLoss:**<br>\n",
    "Purpose: A wrapper class for loss functions, possibly to adjust the behavior of the loss based on the criterion.<br>\n",
    "Parameters:\n",
    "* loss_function: The base loss function(cross entropy loss).\n",
    "* criterion: Specifies the type of loss (cross entropy).\n",
    "Role: This class adjusts the prediction or the format of the output and target (e.g., squeezing dimensions) before passing them to the actual loss function. This is useful in cases where the loss function expects inputs in a specific format.\n",
    "\n",
    "**5. initialize_loss:**<br>\n",
    "Purpose: Initializes the loss function and potentially a loss weight scheduler.\n",
    "Parameters:\n",
    "* cfg: Configuration that specifies the type of loss and any special considerations like dynamic weights.\n",
    "* train_dataset: Dataset to potentially use for dynamic loss weighting.\n",
    "Role: Sets up the loss function according to the specified criteria and initializes dynamic weight, LossWeightsScheduler() adjustments if specified in the configuration.\n",
    "\n",
    "**6. initialize_dataloader**<br>\n",
    "Purpose: Sets up data loaders for training and validation datasets.\n",
    "Parameters:\n",
    "* cfg: Training configuration including batch size and worker details.\n",
    "* train_dataset: Training dataset.\n",
    "* val_dataset: Validation dataset.\n",
    "* train_sampler: Sampler for training dataset.\n",
    "* val_sampler: Sampler for validation dataset (if any).\n",
    "Role: Configures DataLoader() with appropriate batch size, samplers, and other parameters to efficiently load data for both training and validation phases.\n",
    "\n",
    "**DataLoader()**<br>\n",
    "In PyTorch, the DataLoader is a versatile utility that automates the process of loading, shuffling, and batching data for training or inference.\n",
    "\n",
    "**7. save_weights:**<br>\n",
    "Purpose: Saves the model's weights to a specified path.\n",
    "Parameters:\n",
    "* model: The model whose weights are to be saved.\n",
    "* save_path: File path where the weights should be saved.\n",
    "\n",
    "Role: Handles saving of model weights, considering whether the model is wrapped in any parallel data processing wrappers like DataParallel.\n",
    "\n",
    "**8. inverse_normalize:**<br>\n",
    "Purpose: Applies inverse normalization to images (typically used for visualizing or processing outputs).\n",
    "Parameters:\n",
    "* tensor: Image data tensor.\n",
    "* mean: Mean used for normalization.\n",
    "* std: Standard deviation used for normalization.\n",
    "\n",
    "Role: Reverses the normalization process to bring images back to their original value range, useful for visualization or post-processing.\n",
    "\n",
    "**9. select_target_type:**<br>\n",
    "Purpose: Adjusts the data type of targets based on the loss criterion.\n",
    "Parameters:\n",
    "* y: Target labels.\n",
    "* criterion: Specifies the loss function type.\n",
    "\n",
    "Role: Ensures that target data types are compatible with the expectations of different loss functions, like converting to long integers for classification losses.\n",
    "\n",
    "**10. train:**<br>\n",
    "Purpose: Orchestrates the entire training process using model.train().\n",
    "Parameters:\n",
    "* cfg: All-encompassing configuration object.\n",
    "* model: The CNN model to be trained.\n",
    "* train_dataset, val_dataset: Datasets for training and validation.\n",
    "* estimator: An object to estimate and report training metrics.\n",
    "* logger: (Optional) Logger for recording training progress.\n",
    "\n",
    "Role: Manages the training loop, including updating samplers, loss weights, learning rates, and logging training metrics. Also, it periodically evaluates the model on the validation set and saves model checkpoints.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 24260, 15580, 11372, 14504, 8136, 19232, 13908, 12000) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\baner\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[1;32mc:\\Users\\baner\\anaconda3\\Lib\\multiprocessing\\queues.py:114\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout):\n\u001b[1;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 201\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(cfg, model, train_dataset, val_dataset, estimator, logger)\u001b[0m\n\u001b[0;32m    199\u001b[0m estimator\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m    200\u001b[0m progress \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28menumerate\u001b[39m(train_loader), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader)) \u001b[38;5;28;01mif\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mbase\u001b[38;5;241m.\u001b[39mprogress \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader)\n\u001b[1;32m--> 201\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\baner\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1179\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[0;32m   1181\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\baner\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\baner\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\baner\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\baner\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1146\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1145\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[1;32m-> 1146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 24260, 15580, 11372, 14504, 8136, 19232, 13908, 12000) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    cfg=cfg,\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    estimator=estimator,\n",
    "    logger=logger\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train function orchestrates the comprehensive training process of a convolutional neural network model on optical coherence tomography (OCT) image data. This function manages various aspects of the training cycle, including data loading, dynamic scheduling of learning rates and sampling, application of loss functions, logging, and validation.\n",
    "\n",
    "**Parameters:**\n",
    "* cfg: Configuration object containing all settings related to the model, training process, optimizer, scheduler, etc.\n",
    "* model: The neural network model that will be trained.\n",
    "* train_dataset: Dataset used for training the model.\n",
    "* val_dataset: Dataset used for validating the model's performance.\n",
    "* estimator: Tool for calculating and storing metrics during training.\n",
    "* logger: Optional logging tool for tracking training progress and metrics.\n",
    "\n",
    "**Process Overview:**\n",
    "* Initialization: Initializes the optimizer and learning rate scheduler as specified in cfg. Configures data loaders for both training and validation datasets, using custom sampling strategies to address issues like class imbalance. Sets up the loss function, with dynamic weighting to handle class imbalances effectively.\n",
    "\n",
    "* Training Loop: Runs for a specified number of epochs, during which, updates the sampling weights for the training data to maintain balance across classes, Adjusts the weights used in the loss function based on class importance or frequency, Applies a warm-up scheduler to gradually increase the learning rate if specified, Processes batches(forward propagation, Computes loss, backpropagation, Logs training metrics, and updates the learning rate), Performs validation at specified intervals to monitor model performance on unseen data, adjusting training strategy based on validation results.\n",
    "\n",
    "* Post-Training: Saves the final model weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(cfg, model, dataloader, criterion, estimator, device):\n",
    "    model.eval()\n",
    "    torch.set_grad_enabled(False)\n",
    "\n",
    "    estimator.reset()\n",
    "    for test_data in dataloader:\n",
    "        X, y = test_data\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        y = select_target_type(y, criterion)\n",
    "        y_pred = model(X)\n",
    "        estimator.update(y_pred, y)\n",
    "\n",
    "    model.train()\n",
    "    torch.set_grad_enabled(True)\n",
    "\n",
    "def evaluate(cfg, model, test_dataset, estimator):\n",
    "    test_sampler = None\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        shuffle=(test_sampler is None),\n",
    "        sampler=test_sampler,\n",
    "        batch_size=cfg.train.batch_size,\n",
    "        num_workers=cfg.train.num_workers,\n",
    "        pin_memory=cfg.train.pin_memory\n",
    "    )\n",
    "\n",
    "    print('Running on Test set...')\n",
    "    eval(cfg, model, test_loader, cfg.train.criterion, estimator, cfg.base.device)\n",
    "\n",
    "    print('================Finished================')\n",
    "    test_scores = estimator.get_scores(6)\n",
    "    for metric, score in test_scores.items():\n",
    "        print('{}: {}'.format(metric, score))\n",
    "    print('Confusion Matrix:')\n",
    "    print(estimator.get_conf_mat())\n",
    "    print('========================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eval and evaluate functions are essential parts of the validation and testing process. These functions are designed to assess the performance of the model on a test or validation set, ensuring that it generalizes well beyond the training data. Below is a detailed explanation of each function, their parameters, purpose, and role in the model's evaluation process:<br>\n",
    "\n",
    "**1. eval Function:**<br>\n",
    "Purpose: Model Evaluation - Conducts a pass through the validation or test dataset to evaluate the model's performance. This function is critical for assessing the model under a non-training condition where no learning is taking place.<br>\n",
    "\n",
    "Parameters:\n",
    "* cfg: Configuration object containing all necessary settings.\n",
    "* model: The CNN model being evaluated.\n",
    "* dataloader: A DataLoader object that provides batches of data from the test or validation set.\n",
    "* criterion: Specifies the loss function used during training, which influences how the data should be prepared or processed.\n",
    "* estimator: An object used to calculate and record various performance metrics.\n",
    "* device: Specifies the computing device (e.g., CPU or CUDA GPU) where the evaluation should run.\n",
    "\n",
    "Role:\n",
    "* Mode Setting: Switches the model to eval mode (model.eval()), which disables dropout and batch normalization effects specific to training.\n",
    "* Gradient Handling: Disables gradient computation(torch.set_grad_enabled(False)), reducing memory usage and speeding up computation, as gradients are not needed for model evaluation.\n",
    "* Metric Calculation: Iterates through the dataset using (dataloader), computes predictions, and uses the estimator to update performance metrics based on the predictions and actual labels.\n",
    "* Reset State: After evaluation, resets the model to training mode and re-enables gradient computation to resume training if needed.\n",
    "\n",
    "**2. evaluate Function:**<br>\n",
    "Purpose: Test Evaluation - Specifically designed to handle the evaluation of the model on a test dataset and to print out the performance metrics and confusion matrix. This function sets up the testing environment, loads the test data, and calls the eval function.\n",
    "Parameters:\n",
    "* cfg: Configuration object containing settings like batch size and device.\n",
    "* model: The CNN model to be tested.\n",
    "* test_dataset: Dataset used for testing the model.\n",
    "* estimator: Metric calculator for evaluating model performance.\n",
    "\n",
    "Role: \n",
    "* DataLoader Setup: Initializes a DataLoader for the test dataset. The DataLoader handles batching, shuffling (if applicable), and allocation of data for processing, based on the configuration settings.\n",
    "* Evaluation Process: Calls the eval function to perform the actual evaluation, passing all necessary configurations and objects.\n",
    "* Performance Output: After evaluation, prints detailed performance metrics and a confusion matrix to provide insights into the model's classification accuracy across different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of the best validation model:\n",
      "================================================================================\n",
      "Load weights form C:/Users/baner/OneDrive/Desktop/New folder (2)/OCTDL/run\\best_validation_weights.pt\n",
      "================================================================================\n",
      "Running on Test set...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 20188, 17164, 17452, 8472, 20120, 6856, 2552, 16460) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\baner\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[1;32mc:\\Users\\baner\\anaconda3\\Lib\\multiprocessing\\queues.py:114\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout):\n\u001b[1;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m cfg\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mcheckpoint \u001b[38;5;241m=\u001b[39m checkpoint\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m generate_model(cfg)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[26], line 29\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(cfg, model, test_dataset, estimator)\u001b[0m\n\u001b[0;32m     19\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[0;32m     20\u001b[0m     test_dataset,\n\u001b[0;32m     21\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m(test_sampler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m     pin_memory\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mpin_memory\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning on Test set...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m================Finished================\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     32\u001b[0m test_scores \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mget_scores(\u001b[38;5;241m6\u001b[39m)\n",
      "Cell \u001b[1;32mIn[26], line 6\u001b[0m, in \u001b[0;36meval\u001b[1;34m(cfg, model, dataloader, criterion, estimator, device)\u001b[0m\n\u001b[0;32m      3\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m estimator\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m----> 6\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\baner\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\baner\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\baner\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\baner\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1146\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1145\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[1;32m-> 1146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 20188, 17164, 17452, 8472, 20120, 6856, 2552, 16460) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "# test\n",
    "print('Performance of the best validation model:')\n",
    "checkpoint = os.path.join(cfg.base.save_path, 'best_validation_weights.pt')\n",
    "cfg.train.checkpoint = checkpoint\n",
    "model = generate_model(cfg)\n",
    "evaluate(cfg, model, test_dataset, estimator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating a trained convolutional neural network (CNN) model on a test dataset. This process is critical in machine learning workflows to assess the generalizability and performance of the model outside of the training environment. Here’s a detailed summary:<br>\n",
    "\n",
    "**Purpose:**<br>\n",
    "The function is designed to load a pre-trained model from a saved checkpoint and then evaluate its performance on a test dataset. This allows for a realistic assessment of how well the model will perform in clinical settings for OCT (Optical Coherence Tomography) image analysis.<br>\n",
    "\n",
    "**Process Overview:**\n",
    "* Model Loading: Checkpoint Retrieval: Constructs a file path to retrieve the best model weights saved during validation (best_validation_weights.pt). This checkpoint contains the state of the model that had the best performance on the validation set during training.\n",
    "* Configuration Update: Updates the training configuration to use the checkpoint file.\n",
    "* Model Initialization: Calls generate_model(cfg), which, Constructs the model architecture specified in the configuration, Loads the model weights from the checkpoint, Transfers the model to the appropriate computational device (e.g., CPU or GPU).\n",
    "* Model Evaluation: Prepares a DataLoader for the test dataset, which automates the batching and optional shuffling of the test data, Calls the evaluate function with the model and test data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of the final model:\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/baner/OneDrive/Desktop/New folder (2)/OCTDL/run\\\\final_weights.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(cfg\u001b[38;5;241m.\u001b[39mbase\u001b[38;5;241m.\u001b[39msave_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_weights.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m cfg\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mcheckpoint \u001b[38;5;241m=\u001b[39m checkpoint\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m evaluate(cfg, model, test_dataset, estimator)\n",
      "Cell \u001b[1;32mIn[12], line 61\u001b[0m, in \u001b[0;36mgenerate_model\u001b[1;34m(cfg)\u001b[0m\n\u001b[0;32m     58\u001b[0m model \u001b[38;5;241m=\u001b[39m build_model(cfg)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mcheckpoint:\n\u001b[1;32m---> 61\u001b[0m     weights \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(weights, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     63\u001b[0m     print_msg(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoad weights form \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(cfg\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mcheckpoint))\n",
      "File \u001b[1;32mc:\\Users\\baner\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:998\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    996\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 998\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\baner\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:445\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 445\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    447\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\baner\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:426\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 426\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/baner/OneDrive/Desktop/New folder (2)/OCTDL/run\\\\final_weights.pt'"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Performance of the final model:')\n",
    "checkpoint = os.path.join(cfg.base.save_path, 'final_weights.pt')\n",
    "cfg.train.checkpoint = checkpoint\n",
    "model = generate_model(cfg)\n",
    "evaluate(cfg, model, test_dataset, estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Verification:**<br>\n",
    "This function acts as the ultimate test for the model's learning and generalization abilities. By evaluating the model with the final weights, it ensures that the training outcomes are reliable and the model is ready for deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
