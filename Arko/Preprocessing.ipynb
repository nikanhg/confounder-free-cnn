{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install opencv-python\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile\n",
    "from os.path import join\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from math import ceil\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting patients with age and sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"C:/Users/baner/OneDrive/Desktop/New folder (2)\"\n",
    "# Path to the CSV file\n",
    "csv_file_path =  dir + '/OCTDL_labels.csv'\n",
    "# Base directory containing the disease folders\n",
    "base_directory = dir +  '/OCTDL images/'\n",
    "\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "image_ids = set(df['file_name'])\n",
    "diseases = df['disease'].unique()\n",
    "\n",
    "\n",
    "for disease in diseases:\n",
    "    disease_folder_path = os.path.join(base_directory, disease)\n",
    "    if not os.path.exists(disease_folder_path):\n",
    "        print(f\"Folder not found: {disease_folder_path}\")\n",
    "        continue\n",
    "    files = os.listdir(disease_folder_path)\n",
    "    \n",
    "    for file in files:\n",
    "        if file.split('.')[0] not in image_ids:\n",
    "            file_path = os.path.join(disease_folder_path, file)\n",
    "            os.remove(file_path)\n",
    "            print(f\"Deleted {file_path}\")\n",
    "\n",
    "print(\"Cleanup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"C:/Users/baner/OneDrive/Desktop/New folder (2)/OCTDL\"\n",
    "#Input \n",
    "dataset_folder = dir + \"/OCTDL images/\"\n",
    "#lables for each Input\n",
    "labels_path = dir + \"/OCTDL_labels.csv\"\n",
    "#Output\n",
    "output_folder = dir + \"/output\"\n",
    "#Defines the ratio for central cropping of images; 1 means no cropping. default=1\n",
    "crop_ratio = 1\n",
    "#Specifies the dimensions to which images should be resized Default is 512\n",
    "image_dim =512\n",
    "#validation set\n",
    "val_ratio = 0.15\n",
    "#test_ratio\n",
    "test_ratio = 0.25\n",
    "#A boolean flag that, when true, indicates images should be padded to become square. Default is False\n",
    "padding = True\n",
    "#A boolean flag that, when true, indicates images should be cropped centrally according to the crop_ratio Default is False.\n",
    "crop = False\n",
    "#A boolean flag that, when true, indicates images should be resized to image_dim. Default is False.\n",
    "resize =True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "describing the directory and data cleaning parameters for preprocessing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['AMD', 'DME', 'ERM', 'NO', 'RAO', 'RVO', 'VID']\n",
    "folders = ['train', 'val', 'test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes and name of folders for cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(img):\n",
    "    \"\"\"Returns padded to square image\n",
    "    \"\"\"\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    if width == height:\n",
    "        return img\n",
    "    elif width > height:\n",
    "        left = 0\n",
    "        right = 0\n",
    "        bottom = ceil((width - height) / 2)\n",
    "        top = ceil((width - height) / 2)\n",
    "        result = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(0, 0, 0)) #cv2.copyMakeBorder is used to apply this padding, where the new borders are filled with black color\n",
    "        return result\n",
    "    else:\n",
    "        left = ceil((height - width) / 2)\n",
    "        right = ceil((height - width) / 2)\n",
    "        bottom = 0\n",
    "        top = 0\n",
    "        result = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "takes an image (referred to as img) and adjusts it so that it becomes a square. It ensures that the width and height of the image are the same by adding black-colored borders where necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It first measures the height and width of the input image. If the width and height are the same, the function just returns the image as it is.\n",
    "\n",
    "*  If the image has more width than height, it calculates how much padding is needed to make the image square and adds it equally to the top and bottom of the image.\n",
    "\n",
    "* If the image has more height than width, it calculates the padding needed and adds it equally to the left and right sides of the image.\n",
    "\n",
    "Note: cv2.copyMakeBorder is used to apply this padding, where the new borders are filled with black color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_crop(img, dim):\n",
    "    \"\"\"Returns center cropped image\n",
    "    \"\"\"\n",
    "    width, height = img.shape[1], img.shape[0]\n",
    "    # process crop width and height for max available dimension\n",
    "    crop_width = dim[0] if dim[0] < img.shape[1] else img.shape[1]\n",
    "    crop_height = dim[1] if dim[1] < img.shape[0] else img.shape[0]\n",
    "    mid_x, mid_y = int(width/2), int(height/2)\n",
    "    cw2, ch2 = int(crop_width/2), int(crop_height/2)\n",
    "    crop_img = img[mid_y-ch2:mid_y+ch2, mid_x-cw2:mid_x+cw2]\n",
    "    return crop_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes an image and a dimensions of the image as input and returns a version of the image that has been cropped around the center to the specified dimensions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It first determines the current width and height of the image by accessing the image’s shape.\n",
    "\n",
    "*  Then checks the desired crop dimensions provided in dim. It then ensures these dimensions do not exceed the image’s actual size. If the desired dimensions are larger than the image, it keeps the orignal dimensions. \n",
    "\n",
    "* It calculates the center point of the image by dividing the width and height by two.\n",
    "\n",
    "* To make sure the cropping is centered, it calculates half the width and half the height of the crop dimensions. This helps in determining the exact boundaries of the crop area.\n",
    "\n",
    "* FInally it calculates where to start and stop the crop in both vertical and horizontal directions. It uses the center of the image as a reference point, and crops it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_image(img, factor=1):\n",
    "    \"\"\"Returns resize image by scale factor.\n",
    "    This helps to retain resolution ratio while resizing.\n",
    "    Args:\n",
    "    img: image to be scaled\n",
    "    factor: scale factor to resize\"\n",
    "    \"\"\"\n",
    "    width = int(img.shape[1] * factor)\n",
    "    height = int(img.shape[0] * factor)\n",
    "    dsize = (width, height)\n",
    "    output = cv2.resize(img, dsize, interpolation=cv2.INTER_LANCZOS4)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function scale_image is designed to resize an image by a given scale factor, keeping the image's proportions the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: cv2.INTER_LANCZOS4 is used for reducing or increasing image size while maintaining high image quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(root_folder, output_folder, file, folder, crop_ratio, dim, label, padding_bool, crop_bool, resize_bool):\n",
    "    img = cv2.imread(os.path.join(root_folder, label, file))\n",
    "    if padding_bool:\n",
    "        img = padding(img)\n",
    "    if crop_bool:\n",
    "        img = center_crop(img, (img.shape[1] * crop_ratio, img.shape[0] * crop_ratio))\n",
    "    if resize_bool:\n",
    "        img = cv2.resize(img, dim, interpolation=cv2.INTER_LANCZOS4)    #cv2.INTER_LANCZOS4 is used for reducing or increasing image size while maintaining high image quality.\n",
    "    cv2.imwrite(os.path.join(output_folder, folder, label, Path(file).name), img, [cv2.IMWRITE_JPEG_QUALITY, 100])  #image is saved with high JPEG quality (100), which means minimal compression and maximal quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calls the functions for resizing, cropping and padding, based on the padding_bool, crop_bool and resize_bool. Then saves the images in output folder -> file_name( train, test, and val) -> disease class -> image name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2064, 10)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_folder = dataset_folder\n",
    "train_ratio = 1 - val_ratio - test_ratio\n",
    "dim = (image_dim, image_dim)\n",
    "padding_bool = padding\n",
    "crop_bool = crop\n",
    "resize_bool = resize\n",
    "#Reading the Labels\n",
    "df = pd.read_csv(labels_path)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disease</th>\n",
       "      <th>Patient count</th>\n",
       "      <th>Percentage Of Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMD</td>\n",
       "      <td>421</td>\n",
       "      <td>51.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DME</td>\n",
       "      <td>107</td>\n",
       "      <td>13.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ERM</td>\n",
       "      <td>71</td>\n",
       "      <td>8.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NO</td>\n",
       "      <td>110</td>\n",
       "      <td>13.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RAO</td>\n",
       "      <td>11</td>\n",
       "      <td>1.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RVO</td>\n",
       "      <td>50</td>\n",
       "      <td>6.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VID</td>\n",
       "      <td>51</td>\n",
       "      <td>6.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  disease  Patient count  Percentage Of Total\n",
       "0     AMD            421                51.28\n",
       "1     DME            107                13.03\n",
       "2     ERM             71                 8.65\n",
       "3      NO            110                13.40\n",
       "4     RAO             11                 1.34\n",
       "5     RVO             50                 6.09\n",
       "6     VID             51                 6.21"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dist = df[['disease','patient_id']].groupby('disease')['patient_id'].nunique().reset_index(name='Patient count')\n",
    "total_unique_patients = class_dist['Patient count'].sum()\n",
    "class_dist['Percentage Of Total'] = ((class_dist['Patient count'] / total_unique_patients) * 100).round(2)\n",
    "class_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in folders:\n",
    "    for label in labels:\n",
    "        Path(os.path.join(output_folder, folder, label)).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates the output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 318.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMD 752 186 293\n",
      "DME 85 22 40\n",
      "ERM 100 18 37\n",
      "NO 208 53 71\n",
      "RAO 15 1 6\n",
      "RVO 59 20 22\n",
      "VID 41 16 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for label in tqdm(labels):\n",
    "        df_label = df[df['disease'] == label][['file_name', 'disease', 'patient_id']]\n",
    "        patients_list = df_label.patient_id.unique()\n",
    "        if len(patients_list) < 10:\n",
    "            print(f\"Skipping {label} due to insufficient data.\")\n",
    "            continue\n",
    "        train_patients, test_patients = train_test_split(patients_list, test_size=1 - train_ratio)\n",
    "        val_patients, test_patients = train_test_split(test_patients, test_size=test_ratio / (test_ratio + val_ratio))\n",
    "        df_label_train = df_label[df_label['patient_id'].isin(train_patients)]\n",
    "        df_label_val = df_label[df_label['patient_id'].isin(val_patients)]\n",
    "        df_label_test = df_label[df_label['patient_id'].isin(test_patients)]\n",
    "        \n",
    "        print(label, len(df_label_train), len(df_label_val), len(df_label_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divides the dataset into training, validation, and test subsets based on patient data for different disease classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It loops through each unique disease class stored in labels. The progress of this loop is tracked using tqdm, (displays a progress bar).\n",
    "* For each disease class, it selects image names, classes, and patient IDs from df that match the current label.\n",
    "* The code identifies unique patient IDs associated with each label. If a disease class has fewer than 10 unique patients\n",
    "* It splits the list of patient IDs into training validation, and test groups based on a ratio \n",
    "* Creates 3 new df for each train, test and val dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(df_label_train)):\n",
    "    file_name = df_label_train.iloc[i, 0] + '.jpg'\n",
    "    file_label = df_label_train.iloc[i, 1]    \n",
    "    preprocessing(root_folder, output_folder, file_name, 'train', crop_ratio, dim, file_label, padding_bool, crop_bool, resize_bool)\n",
    "\n",
    "for i in range(0, len(df_label_test)):\n",
    "    file_name = df_label_test.iloc[i, 0] + '.jpg'\n",
    "    file_label = df_label_test.iloc[i, 1]    \n",
    "    preprocessing(root_folder, output_folder, file_name, 'test', crop_ratio, dim, file_label, padding_bool, crop_bool, resize_bool)    \n",
    "\n",
    "for i in range(0, len(df_label_val)):\n",
    "    file_name = df_label_val.iloc[i, 0] + '.jpg'\n",
    "    file_label = df_label_val.iloc[i, 1]    \n",
    "    preprocessing(root_folder, output_folder, file_name, 'val', crop_ratio, dim, file_label, padding_bool, crop_bool, resize_bool) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executes the function preprocessing for each df(train, validation, and test) which in-turn calls the functions for resizing, cropping and padding."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
