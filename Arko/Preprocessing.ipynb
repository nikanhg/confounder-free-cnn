{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCTDL Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is designed for preprocessing a OCTDL, which is a crucial step in preparing data for training machine learning models, particularly in medical imaging tasks. Preprocessing ensures that the input data is consistent in format, size, and type, which helps in achieving better performance and more reliable results from the models. Optical coherence tomography (OCT) is a non-invasive imaging technique with extensive clinical applications in ophthalmology. OCT enables the visualization of the retinal layers, playing a vital role in the early detection and monitoring of retinal diseases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Data Cleaning: To ensure the dataset only contains relevant and properly labeled images.\n",
    "\n",
    "* Data Splitting: To divide the data into training, validation, and test sets based on patient IDs. This separation is important to avoid data leakage where information from the test set is known during training, potentially leading to overfitting and poor model generalization.\n",
    "\n",
    "* Image Preprocessing: To standardize the images by resizing, cropping, and padding. This uniformity is crucial for the algorithm to learn effectively without bias from varying image sizes or scales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The dataset comprises 2064 images originating from 821 distinct patients. The dataset is meticulously organized, with each image accompanied by a detailed metadata record in a CSV file. This file encapsulates various attributes such as ‘file_name’, ‘disease’, ‘subcategory’, ‘condition’, ‘patient_id’, ‘eye’, ‘sex’, ‘year’, ‘image_width’, and ‘image_height’. Here, the ‘year’ attribute specifically denotes the year the image was taken, providing temporal context which could be relevant for longitudinal studies or tracking disease progression.\n",
    "\n",
    "This dataset encapsulates a broad spectrum of seven disease classes, which include: \n",
    "* Age-related Macular Degeneration (AMD)\n",
    "* Diabetic Macular Edema (DME)\n",
    "* Epiretinal Membrane (ERM) \n",
    "* Retinal Artery Occlusion (RAO)\n",
    "* Vitreoretinal Interface Disease (VID)\n",
    "* Retinal Vein Occlusion (RVO)\n",
    "* Normal (NO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These classes form the basis for developing predictive models that aim to diagnose these conditions from the retinal images. The notebook's setup for preprocessing — including cleaning, splitting, and standardizing the images — is tailored to prepare this dataset for subsequent analysis and model training, ensuring that the data used in training, validation, and testing phases is representative, balanced, and adheres strictly to the required input format for deep learning models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install opencv-python\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile\n",
    "from os.path import join\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from math import ceil\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"C:/Users/baner/OneDrive/Desktop/New folder (2)/OCTDL\"\n",
    "#Input \n",
    "dataset_folder = dir + \"/OCTDL images/\"\n",
    "#lables for each Input\n",
    "labels_path = dir + \"/OCTDL_labels.csv\"\n",
    "#Output\n",
    "output_folder = dir + \"/output\"\n",
    "#Defines the ratio for central cropping of images; 1 means no cropping. default=1\n",
    "crop_ratio = 1\n",
    "#Specifies the dimensions to which images should be resized Default is 512\n",
    "image_dim =512\n",
    "#validation set\n",
    "val_ratio = 0.15\n",
    "#test_ratio\n",
    "test_ratio = 0.25\n",
    "#A boolean flag that, when true, indicates images should be padded to become square. Default is False\n",
    "padding = True\n",
    "#A boolean flag that, when true, indicates images should be cropped centrally according to the crop_ratio Default is False.\n",
    "crop = False\n",
    "#A boolean flag that, when true, indicates images should be resized to image_dim. Default is False.\n",
    "resize =True\n",
    "folders = ['train', 'val', 'test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "describing the directory and data cleaning parameters for preprocessing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(img):\n",
    "    \"\"\"Returns padded to square image\n",
    "    \"\"\"\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    if width == height:\n",
    "        return img\n",
    "    elif width > height:\n",
    "        left = 0\n",
    "        right = 0\n",
    "        bottom = ceil((width - height) / 2)\n",
    "        top = ceil((width - height) / 2)\n",
    "        result = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(0, 0, 0)) #cv2.copyMakeBorder is used to apply this padding, where the new borders are filled with black color\n",
    "        return result\n",
    "    else:\n",
    "        left = ceil((height - width) / 2)\n",
    "        right = ceil((height - width) / 2)\n",
    "        bottom = 0\n",
    "        top = 0\n",
    "        result = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "takes an image (referred to as img) and adjusts it so that it becomes a square. It ensures that the width and height of the image are the same by adding black-colored borders where necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It first measures the height and width of the input image. If the width and height are the same, the function just returns the image as it is.\n",
    "\n",
    "*  If the image has more width than height, it calculates how much padding is needed to make the image square and adds it equally to the top and bottom of the image.\n",
    "\n",
    "* If the image has more height than width, it calculates the padding needed and adds it equally to the left and right sides of the image.\n",
    "\n",
    "Note: cv2.copyMakeBorder is used to apply this padding, where the new borders are filled with black color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_crop(img, dim):\n",
    "    \"\"\"Returns center cropped image\n",
    "    \"\"\"\n",
    "    width, height = img.shape[1], img.shape[0]\n",
    "    # process crop width and height for max available dimension\n",
    "    crop_width = dim[0] if dim[0] < img.shape[1] else img.shape[1]\n",
    "    crop_height = dim[1] if dim[1] < img.shape[0] else img.shape[0]\n",
    "    mid_x, mid_y = int(width/2), int(height/2)\n",
    "    cw2, ch2 = int(crop_width/2), int(crop_height/2)\n",
    "    crop_img = img[mid_y-ch2:mid_y+ch2, mid_x-cw2:mid_x+cw2]\n",
    "    return crop_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes an image and a dimensions of the image as input and returns a version of the image that has been cropped around the center to the specified dimensions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It first determines the current width and height of the image by accessing the image’s shape.\n",
    "\n",
    "*  Then checks the desired crop dimensions provided in dim. It then ensures these dimensions do not exceed the image’s actual size. If the desired dimensions are larger than the image, it keeps the orignal dimensions. \n",
    "\n",
    "* It calculates the center point of the image by dividing the width and height by two.\n",
    "\n",
    "* To make sure the cropping is centered, it calculates half the width and half the height of the crop dimensions. This helps in determining the exact boundaries of the crop area.\n",
    "\n",
    "* FInally it calculates where to start and stop the crop in both vertical and horizontal directions. It uses the center of the image as a reference point, and crops it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_image(img, factor=1):\n",
    "    width = int(img.shape[1] * factor)\n",
    "    height = int(img.shape[0] * factor)\n",
    "    dsize = (width, height)\n",
    "    output = cv2.resize(img, dsize, interpolation=cv2.INTER_LANCZOS4)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function scale_image is designed to resize an image by a given scale factor, keeping the image's proportions the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: cv2.INTER_LANCZOS4 is used for reducing or increasing image size while maintaining high image quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(root_folder, output_folder, file, folder, crop_ratio, dim, label, padding_bool, crop_bool, resize_bool):\n",
    "    img = cv2.imread(os.path.join(root_folder, label, file))\n",
    "    if padding_bool:\n",
    "        img = padding(img)\n",
    "    if crop_bool:\n",
    "        img = center_crop(img, (img.shape[1] * crop_ratio, img.shape[0] * crop_ratio))\n",
    "    if resize_bool:\n",
    "        img = cv2.resize(img, dim, interpolation=cv2.INTER_LANCZOS4)    #cv2.INTER_LANCZOS4 is used for reducing or increasing image size while maintaining high image quality.\n",
    "    cv2.imwrite(os.path.join(output_folder, folder, label, Path(file).name), img, [cv2.IMWRITE_JPEG_QUALITY, 100])  #image is saved with high JPEG quality (100), which means minimal compression and maximal quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calls the functions for resizing, cropping and padding, based on the padding_bool, crop_bool and resize_bool. Then saves the images in output folder -> file_name( train, test, and val) -> disease class -> image name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disease</th>\n",
       "      <th>Patient count</th>\n",
       "      <th>Percentage Of Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMD</td>\n",
       "      <td>148</td>\n",
       "      <td>78.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DME</td>\n",
       "      <td>1</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ERM</td>\n",
       "      <td>12</td>\n",
       "      <td>6.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NO</td>\n",
       "      <td>16</td>\n",
       "      <td>8.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RVO</td>\n",
       "      <td>4</td>\n",
       "      <td>2.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VID</td>\n",
       "      <td>7</td>\n",
       "      <td>3.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  disease  Patient count  Percentage Of Total\n",
       "0     AMD            148                78.72\n",
       "1     DME              1                 0.53\n",
       "2     ERM             12                 6.38\n",
       "3      NO             16                 8.51\n",
       "4     RVO              4                 2.13\n",
       "5     VID              7                 3.72"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_folder = dataset_folder\n",
    "train_ratio = 1 - val_ratio - test_ratio\n",
    "dim = (image_dim, image_dim)\n",
    "padding_bool = padding\n",
    "crop_bool = crop\n",
    "resize_bool = resize\n",
    "#Reading the Labels\n",
    "df = pd.read_csv(labels_path)\n",
    "df= df[df['sex'] != '0']\n",
    "\n",
    "labels = df['disease'].unique()\n",
    "labels = labels.tolist()\n",
    "\n",
    "image_ids = set(df['file_name'])\n",
    "base_directory = dir +  '/OCTDL images/'\n",
    "diseases = df['disease'].unique()\n",
    "\n",
    "for disease in diseases:\n",
    "    disease_folder_path = os.path.join(dataset_folder, disease)\n",
    "    \n",
    "    if not os.path.exists(disease_folder_path):\n",
    "        print(f\"Folder not found: {disease_folder_path}\")\n",
    "        continue\n",
    "    \n",
    "    files = os.listdir(disease_folder_path)\n",
    "    \n",
    "    for file in files:\n",
    "        if file.split('.')[0] not in image_ids:\n",
    "            file_path = os.path.join(disease_folder_path, file)\n",
    "            os.remove(file_path)\n",
    "            print(f\"Deleted {file_path}\")\n",
    "\n",
    "class_dist = df[['disease','patient_id']].groupby('disease')['patient_id'].nunique().reset_index(name='Patient count')\n",
    "total_unique_patients = class_dist['Patient count'].sum()\n",
    "class_dist['Percentage Of Total'] = ((class_dist['Patient count'] / total_unique_patients) * 100).round(2)\n",
    "class_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we focus on ensuring that only images associated with patients who have valid sex  are retained. This preprocessing is crucial in the context of analyzing and comparing the performance of two types of neural networks: Convolutional Neural Networks (CNN) and Confounder Free Neural Networks (CF-NET), with sex as confounding variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in folders:\n",
    "    for label in labels:\n",
    "        df_label = df[df['disease'] == label][['file_name', 'disease', 'patient_id']]\n",
    "        patients_list = df_label.patient_id.unique() \n",
    "        if len(patients_list) < 10:\n",
    "            continue\n",
    "        Path(os.path.join(output_folder, folder, label)).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates the output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMD 196 50 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:06<00:34,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping DME due to insufficient data.\n",
      "ERM 13 2 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:07<00:05,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO 28 6 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:08<00:00,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping RVO due to insufficient data.\n",
      "Skipping VID due to insufficient data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "label_new = []\n",
    "for label in tqdm(labels):\n",
    "        df_label = df[df['disease'] == label][['file_name', 'disease', 'patient_id']]\n",
    "        patients_list = df_label.patient_id.unique() \n",
    "\n",
    "        if len(patients_list) < 10:\n",
    "            print(f\"Skipping {label} due to insufficient data.\")\n",
    "            continue\n",
    "        label_new.append(label)\n",
    "        train_patients, test_patients = train_test_split(patients_list, test_size=1 - train_ratio)\n",
    "        val_patients, test_patients = train_test_split(test_patients, test_size=test_ratio / (test_ratio + val_ratio))\n",
    "        df_label_train = df_label[df_label['patient_id'].isin(train_patients)]\n",
    "        df_label_val = df_label[df_label['patient_id'].isin(val_patients)]\n",
    "        df_label_test = df_label[df_label['patient_id'].isin(test_patients)]\n",
    "        \n",
    "        print(label, len(df_label_train), len(df_label_val), len(df_label_test))\n",
    "        for i in range(0, len(df_label_train)):\n",
    "            file_name = df_label_train.iloc[i, 0] + '.jpg'\n",
    "            file_label = df_label_train.iloc[i, 1]    \n",
    "            preprocessing(root_folder, output_folder, file_name, 'train', crop_ratio, dim, file_label, padding_bool, crop_bool, resize_bool)\n",
    "\n",
    "        for i in range(0, len(df_label_test)):\n",
    "            file_name = df_label_test.iloc[i, 0] + '.jpg'\n",
    "            file_label = df_label_test.iloc[i, 1]    \n",
    "            preprocessing(root_folder, output_folder, file_name, 'test', crop_ratio, dim, file_label, padding_bool, crop_bool, resize_bool)    \n",
    "\n",
    "        for i in range(0, len(df_label_val)):\n",
    "            file_name = df_label_val.iloc[i, 0] + '.jpg'\n",
    "            file_label = df_label_val.iloc[i, 1]    \n",
    "            preprocessing(root_folder, output_folder, file_name, 'val', crop_ratio, dim, file_label, padding_bool, crop_bool, resize_bool)\n",
    "\n",
    "\n",
    "labels = label_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divides the dataset into training, validation, and test subsets based on patient data for different disease classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It loops through each unique disease class stored in labels. The progress of this loop is tracked using tqdm, (displays a progress bar).\n",
    "* For each disease class, it selects image names, classes, and patient IDs from df that match the current label.\n",
    "* The code identifies unique patient IDs associated with each label. If a disease class has fewer than 10 unique patients it skips it\n",
    "* It splits the list of patient IDs into training validation, and test groups based on a ratio \n",
    "* Creates 3 new df for each train, test and val dataset\n",
    "* Executes the function preprocessing for each df(train, validation, and test) which in-turn calls the functions for resizing, cropping and padding."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
